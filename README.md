# ğŸ› ï¸ Monitoring Awarii Maszyn â€“ Projekt Real-Time Analytics

Projekt stworzony w ramach przedmiotu *Analiza danych w czasie rzeczywistym*.  
Celem jest wykrywanie potencjalnych awarii maszyn na podstawie danych strumieniowych oraz podejmowanie decyzji biznesowych w czasie rzeczywistym.

---

## ğŸ¯ Cel biznesowy

System analizuje dane z czujnikÃ³w maszyn (temperatura, moment obrotowy, zuÅ¼ycie narzÄ™dzia, itd.) i przewiduje, czy istnieje ryzyko awarii.  
JeÅ›li prawdopodobieÅ„stwo awarii przekracza okreÅ›lony prÃ³g, generowany jest alert, ktÃ³ry moÅ¼e byÄ‡ podstawÄ… do:

- zatrzymania maszyny,
- wezwania serwisu,
- wysÅ‚ania powiadomienia do operatora.

---

## ğŸ§± Architektura

System skÅ‚ada siÄ™ z nastÄ™pujÄ…cych komponentÃ³w:

- **Kafka + Zookeeper** â€“ poÅ›rednik danych (Docker)
- **Producer (`kafka_producer.py`)** â€“ symuluje dane w czasie rzeczywistym (CSV â†’ Kafka)
- **Model ML (`model.pkl`)** â€“ klasyfikator Random Forest
- **Consumer (`kafka_consumer_ml_log.py`)** â€“ odbiera dane, analizuje, zapisuje alerty
- **Dashboard (`alert_dashboard.py`)** â€“ wizualizacja alertÃ³w na Å¼ywo (Streamlit)

---

## ğŸ“¦ Pliki

| Plik                         | Opis                                           |
|-----------------------------|------------------------------------------------|
| `docker-compose.yml`        | Uruchamia Kafka i Zookeeper w Dockerze        |
| `train_model.py`            | Trenuje model ML i zapisuje `model.pkl`       |
| `kafka_producer.py`         | WysyÅ‚a dane z `simulation_data.csv` do Kafka |
| `kafka_consumer_ml_log.py`  | Przetwarza dane i zapisuje alerty             |
| `alert_dashboard.py`        | Dashboard w czasie rzeczywistym (Streamlit)   |
| `train_data.csv`            | Dane treningowe                               |
| `simulation_data.csv`       | Dane symulacyjne                              |
| `model.pkl`                 | Zapisany model Random Forest                  |

---

## ğŸš€ Uruchomienie krok po kroku

1. **Zbuduj i uruchom Kafka + Zookeeper**  
```bash
docker-compose up -d
```

2. **UtwÃ³rz topic Kafka**  
```bash
docker exec -it kafka /usr/bin/kafka-topics --create --topic sensor_stream --bootstrap-server localhost:9092
```

3. **(Opcjonalnie) Wytrenuj model ML**  
```bash
python train_model.py
```

4. **Uruchom producer (symulacja danych)**  
```bash
python kafka_producer.py
```

5. **Uruchom consumer z modelem ML**  
```bash
python kafka_consumer_ml_log.py
```

6. **Uruchom dashboard Streamlit**  
```bash
streamlit run alert_dashboard.py
```

---

## ğŸ§  Zastosowane technologie

- Python, Pandas, Scikit-learn
- Apache Kafka (`kafka-python`)
- Docker, Docker Compose
- Streamlit

---

## ğŸ“ˆ MoÅ¼liwoÅ›ci rozbudowy

- Integracja z bazÄ… danych
- Powiadomienia e-mail / SMS
- Lepszy UI dashboardu
- Wersja chmurowa (Kafka + ML w chmurze)
